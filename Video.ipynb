{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import csv\n",
    "import os\n",
    "import datetime\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "\n",
    "import flow_transforms\n",
    "import models\n",
    "import datasets\n",
    "import balancedsampler\n",
    "from multiscaleloss import multiscaleloss\n",
    "from flow_algo import flow_to_color\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model preparation\n",
    "=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--div-flow'], dest='div_flow', nargs=None, const=None, default=20, type=None, choices=None, help='value by which flow will be divided. Original value is 20 but 1 with batchNorm gives good results', metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\"))\n",
    "\n",
    "dataset_names = sorted(name for name in datasets.__all__)\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch FlowNet Training on several datasets')\n",
    "parser.add_argument('data', metavar='DIR',\n",
    "                    help='path to dataset')\n",
    "parser.add_argument('--dataset', metavar='DATASET', default='flying_chairs',\n",
    "                    choices=dataset_names,\n",
    "                    help='dataset type : ' +\n",
    "                        ' | '.join(dataset_names) +\n",
    "                        ' (default: flying_chairs)')\n",
    "parser.add_argument('-s', '--split', default=80, type=float, metavar='%',\n",
    "                    help='split percentage of train samples vs test (default: 80)')\n",
    "parser.add_argument('--arch', '-a', metavar='ARCH', default='flownets',\n",
    "                    choices=model_names,\n",
    "                    help='model architecture: ' +\n",
    "                        ' | '.join(model_names) +\n",
    "                        ' (default: flownets)')\n",
    "parser.add_argument('--solver', default = 'adam',choices=['adam','sgd'],\n",
    "                    help='solvers: adam | sgd')\n",
    "parser.add_argument('-j', '--workers', default=4, type=int, metavar='N',\n",
    "                    help='number of data loading workers (default: 4)')\n",
    "parser.add_argument('--epochs', default=90, type=int, metavar='N',\n",
    "                    help='number of total epochs to run (default: 90')\n",
    "parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
    "                    help='manual epoch number (useful on restarts)')\n",
    "parser.add_argument('--epoch-size', default=0, type=int, metavar='N',\n",
    "                    help='manual epoch size (will match dataset size if not set)')\n",
    "parser.add_argument('-b', '--batch-size', default=16, type=int,\n",
    "                    metavar='N', help='mini-batch size (default: 16)')\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.0001, type=float,\n",
    "                    metavar='LR', help='initial learning rate')\n",
    "parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n",
    "                    help='momentum for sgd, alpha parameter for adam')\n",
    "parser.add_argument('--beta', default=0.999, type=float, metavar='M',\n",
    "                    help='beta parameters for adam')\n",
    "parser.add_argument('--weight-decay', '--wd', default=4e-4, type=float,\n",
    "                    metavar='W', help='weight decay (default: 4e-4)')\n",
    "parser.add_argument('--print-freq', '-p', default=10, type=int,\n",
    "                    metavar='N', help='print frequency (default: 10)')\n",
    "parser.add_argument('--resume', default='', type=str, metavar='PATH',\n",
    "                    help='path to latest checkpoint (default: none)')\n",
    "parser.add_argument('-e', '--evaluate', dest='evaluate', action='store_true',\n",
    "                    help='evaluate model on validation set')\n",
    "parser.add_argument('--pretrained', dest='pretrained', default = None,\n",
    "                    help='path to pre-trained model')\n",
    "parser.add_argument('--log-summary', default = 'progress_log_summary.csv',\n",
    "                    help='csv where to save per-epoch train and test stats')\n",
    "parser.add_argument('--log-full', default = 'progress_log_full.csv',\n",
    "                    help='csv where to save per-gradient descent train stats')\n",
    "parser.add_argument('--no-date', action='store_true',\n",
    "                    help='don\\'t append date timestamp to folder' )\n",
    "parser.add_argument('--loss', default='L1', help='loss function to apply to multiScaleCriterion : L1 (default)| SmoothL1| MSE')\n",
    "parser.add_argument('--div-flow', default = 20,\n",
    "                    help='value by which flow will be divided. Original value is 20 but 1 with batchNorm gives good results')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "args = parser.parse_args(['--pretrained', 'flownets_pytorch.pth', '-e', '-s', '0', '-b', '1',\n",
    "                          '--arch' , 'flownets', 'data'])\n",
    "# evaluate, split at 0%, batchsize 1\n",
    "# without argv[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(arch='flownets', batch_size=1, beta=0.999, data='data', dataset='flying_chairs', div_flow=20, epoch_size=0, epochs=90, evaluate=True, log_full='progress_log_full.csv', log_summary='progress_log_summary.csv', loss='L1', lr=0.0001, momentum=0.9, no_date=False, pretrained='flownets_pytorch.pth', print_freq=10, resume='', solver='adam', split=0.0, start_epoch=0, weight_decay=0.0004, workers=4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "input_transform = transforms.Compose([\n",
    "        flow_transforms.ArrayToTensor(),\n",
    "        transforms.Normalize(mean=[0,0,0], std=[255,255,255]),\n",
    "        normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = models.__dict__[args.arch](args.pretrained).cuda()\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "model = model.eval()\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video capture\n",
    "=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap.isOpened()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_size = (512, 384) # here it's (width, height) order for cv2.resize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loop():\n",
    "    prev = None\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.resize(frame, (data_size), interpolation = cv2.INTER_AREA) # 480 * 640 -> 384 * 512\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    #     cv2.imshow('frame', frame)\n",
    "\n",
    "        # dims: height, width, channels -> batchsize = 1, channels, height, width\n",
    "        if prev is not None:\n",
    "            inp = [prev, frame]\n",
    "            inp = map(input_transform, inp)\n",
    "\n",
    "            input_var = torch.autograd.Variable(torch.cat(inp, 0).cuda(), volatile=True)\n",
    "            input_var = input_var.view(1, *input_var.size())\n",
    "            output = model(input_var) # performs 160ms => 6 fps; 80% of loop time on my laptop card\n",
    "\n",
    "            # dims: batchsize = 1, channels, height, width -> height, width, channels\n",
    "            flow = output.data.cpu().numpy()\n",
    "            flow = flow.reshape(flow.shape[1:])\n",
    "            flow = np.moveaxis(flow, 0, 2)\n",
    "\n",
    "            img = flow_to_color(flow, norm = False)\n",
    "\n",
    "            img = np.flip(img, 2) # RGB to BGR. v2.cvtColor(img, cv2.COLOR_RGB2BGR) throws an error for some reason\n",
    "            img = cv2.resize(img, data_size) # bilinear interpolation\n",
    "            cv2.imshow('flow', img)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        prev = frame\n",
    "\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loop()\n",
    "# %lprun -f loop loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python2",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
